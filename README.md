# Nutriâ€‘GPT

An endâ€‘toâ€‘end GenAI application that uses image + text inputs via the OpenAI vision/chat API to identify foods, estimate calories and nutritional content, with a Streamlitâ€‘based web UI.  
Ideal for prototyping visual food recognition, nutrition analytics and AIâ€‘assisted meal logging.

---

## ğŸš€ Features
- Upload an image of a meal (via `app.py`) â†’ prompt the OpenAI model with a structured â€œfood recognitionâ€ request.  
- Parses the modelâ€™s response into structured nutrition data (food items, serving sizes, calories, macronutrients).  
- Displays detected items, allows manual corrections of calorie/protein values, and exports results as JSON.  
- Lightweight architecture with modular Python code (client wrapper, image utilities, nutrition lookup, parsing logic).  
- Built with Streamlit for quick UI deployment.

---

## ğŸ§± Project Structure

```
nutriâ€‘gpt/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ app.py                â† Streamlit user interface
â”œâ”€ pyproject.toml        â† project metadata (if using Poetry/Flit)
â”œâ”€ calorie_scout/        â† main package
â”‚    â”œâ”€ __init__.py
â”‚    â”œâ”€ config.py        â† loads environment (API key, model defaults)
â”‚    â”œâ”€ image_utils.py   â† image loading/encoding utilities
â”‚    â”œâ”€ openai_client.py â† wrapper for OpenAI vision/chat calls
â””â”€ tests/                â† (optional) unit tests for parsing logic
```

---

## ğŸ› ï¸ Setup & Usage

### 1. Install dependencies  
```bash
pip install -r requirements.txt
```

### 2. Set your OpenAI API key  
- Either export as environment variable:  
  ```bash
  export OPENAI_API_KEY="your-key-here"
  ```  
- Or enter it within the Streamlit sidebar when running the app.

### 3. Run the Streamlit app  
```bash
streamlit run app.py
```

### 4. Upload a food image â†’ view detections â†’ edit values â†’ export JSON  
The UI guides you through uploading a picture, sending the prompt, viewing the model output.
---

## ğŸ“ How it Works (Architecture)

1. The user uploads an image via the Streamlit UI.  
2. `openai_client.OpenAIVisionClient` encodes the image (base64) and sends a prompt to the OpenAI model with â€œfood recognitionâ€ instructions.  
3. The response generated from the LLM will be given back to the streamlit app to display in the webui. 
4. The UI displays Typical Ingredients, Nutritional Profile, Advantages and Disadvantages.



```mermaid
flowchart LR
    U[User Browser] --> UI[Streamlit UI app.py]
    UI --> Img[Image Upload]
    UI --> Client[OpenAIVisionClient]
    Client --> API[OpenAI Vision Chat API]
    API --> Client
    Client --> U[User Browser]
```

---

## ğŸ§© Extending or Customizing

Here are some ideas for enhancing the project:

- **Kiosk or mobile UI variant** â€“ Deploy the UI as a mobileâ€‘friendly web page or convert to a PWA.  
- **Prompt tuning** â€“ Refine the model instructions (prompts) to improve detection accuracy and format consistency.  
- **Caching and rateâ€‘limiting** â€“ Add local caching of model responses or lookup results to reduce cost and latency.

---

## âœ… License & Contribution  
Feel free to fork this repository, send pull requests, and adapt the code for your use case. This project is released under the MIT License unless otherwise specified.  

---

## ğŸ“¬ Contact  
If you have questions or suggestions, feel free to open an Issue or drop a message via GitHub.

Thanks for checking out Nutriâ€‘GPT â€” I hope you have fun prototyping smart foodâ€‘nutrition applications! ğŸ´  